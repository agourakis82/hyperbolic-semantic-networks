# Experiment 1: Epistemic Uncertainty in Curvature Estimates

**Status**: Design phase
**Demetrios Advantage**: Automatic uncertainty propagation through epistemic computing

---

## Scientific Question

**How does curvature uncertainty vary with network size, density, and measurement quality?**

Specifically:
1. Does uncertainty decrease with network size (N)?
2. Does uncertainty increase near the phase transition?
3. Can we quantify confidence in geometry classification?
4. How does Sinkhorn convergence affect uncertainty?

---

## Hypothesis

**H1**: Larger networks yield higher confidence curvature estimates
- More edges â†’ better statistics â†’ lower uncertainty

**H2**: Transition zone (âŸ¨kâŸ©Â²/N â‰ˆ 2.5) has highest uncertainty
- Îº â‰ˆ 0 â†’ small changes matter â†’ higher uncertainty

**H3**: Sinkhorn convergence directly correlates with epistemic confidence
- Better convergence â†’ higher confidence

---

## Experimental Design

### Phase 1: Synthetic Networks

Generate random regular graphs with varying parameters:

| Parameter | Values | Purpose |
|-----------|--------|---------|
| N (nodes) | 50, 100, 200, 500 | Test size effect |
| k (degree) | 3, 10, 22, 30, 40 | Span phase transition |
| Î± (laziness) | 0.0, 0.5 | Standard vs lazy walk |
| Îµ (Sinkhorn) | 0.01, 0.1 | Regularization effect |

**Total**: 4 Ã— 5 Ã— 2 Ã— 2 = 80 network configurations
**Replicates**: 10 per configuration = **800 measurements**

### Phase 2: Real Networks

Apply to semantic networks:
- Spanish SWOW (N=9,246, âŸ¨kâŸ©=3.0)
- English SWOW (N=10,571, âŸ¨kâŸ©=3.1)
- Chinese SWOW (N=8,857, âŸ¨kâŸ©=3.2)
- Dutch SWOW (N=2,962, âŸ¨kâŸ©=61.6)

Compare epistemic uncertainty across languages.

---

## Implementation

### Demetrios Code

```d
module experiments::epistemic_uncertainty

use graph::types::{Graph, NetworkStats};
use graph::curvature::{mean_curvature_epistemic, CurvatureParams};
use graph::random::random_regular_graph;

// Epistemic result with full uncertainty tracking
pub struct EpistemicResult {
    pub n: usize,
    pub k: usize,
    pub ratio: f64,
    pub kappa_value: f64,
    pub kappa_uncertainty: f64,
    pub confidence: f64,
    pub geometry: Geometry,
    pub sinkhorn_iters: usize,
}

// Run single trial with epistemic tracking
pub fn run_trial(n: usize, k: usize, params: CurvatureParams)
    -> EpistemicResult with Alloc, Random, Confidence {

    // Generate network
    let g = random_regular_graph(n, k, 100).unwrap();

    // Compute stats
    let stats = NetworkStats::from_graph(&g);

    // Compute curvature WITH epistemic tracking
    let kappa = mean_curvature_epistemic(&g, params);

    EpistemicResult {
        n,
        k,
        ratio: stats.sparsity_ratio,
        kappa_value: kappa.value(),
        kappa_uncertainty: kappa.uncertainty(),  // â† Automatic from Demetrios!
        confidence: kappa.confidence(),          // â† Automatic confidence level
        geometry: Geometry::from_curvature(kappa.value()),
        sinkhorn_iters: kappa.metadata().iterations,
    }
}

// Run full experiment sweep
pub fn run_experiment() -> [EpistemicResult] with Alloc, Random, Confidence {
    let n_values = [50, 100, 200, 500];
    let k_values = [3, 10, 22, 30, 40];
    let alpha_values = [0.0, 0.5];
    let epsilon_values = [0.01, 0.1];

    var results: [EpistemicResult] = [];

    // Sweep parameters
    for n in n_values {
        for k in k_values {
            for alpha in alpha_values {
                for epsilon in epsilon_values {
                    let params = CurvatureParams {
                        alpha,
                        epsilon,
                        max_iter: 1000,
                    };

                    // 10 replicates per configuration
                    var rep: usize = 0;
                    while rep < 10 {
                        let result = run_trial(n, k, params);
                        results.push(result);
                        rep = rep + 1;
                    }
                }
            }
        }
    }

    results
}
```

### Comparison: Julia Bootstrap

```julia
# Compare Demetrios epistemic uncertainty to bootstrap confidence intervals
using Statistics, Bootstrap

function bootstrap_curvature(g::Graph, n_samples=1000)
    edge_curvatures = compute_all_curvatures(g)

    # Bootstrap resample
    bootstrap_means = [
        mean(sample(edge_curvatures, length(edge_curvatures)))
        for _ in 1:n_samples
    ]

    mean_Îº = mean(edge_curvatures)
    ci = quantile(bootstrap_means, [0.025, 0.975])

    return (
        mean = mean_Îº,
        lower = ci[1],
        upper = ci[2],
        uncertainty = (ci[2] - ci[1]) / 4  # ~95% CI â†’ std
    )
end
```

**Question**: Does Demetrios epistemic uncertainty match bootstrap uncertainty?

---

## Measurements

### Primary Outcomes

1. **Îº_value** - Mean curvature
2. **Îº_uncertainty** - Epistemic uncertainty (from Demetrios)
3. **confidence** - Confidence level (0-1)
4. **geometry** - Classification (Hyperbolic/Euclidean/Spherical)

### Secondary Outcomes

5. **sinkhorn_iters** - Convergence iterations
6. **sinkhorn_residual** - Final residual
7. **execution_time** - Wall clock time
8. **memory_usage** - Peak memory

### Derived Metrics

9. **uncertainty_vs_N** - Does uncertainty âˆ 1/âˆšN?
10. **uncertainty_vs_ratio** - Peak at âŸ¨kâŸ©Â²/N â‰ˆ 2.5?
11. **confidence_vs_geometry** - Higher for extreme geometries?
12. **epistemic_vs_bootstrap** - Correlation with Julia bootstrap?

---

## Analysis Plan

### Statistical Tests

1. **Effect of N on uncertainty**:
   - Linear regression: log(uncertainty) ~ log(N)
   - Expected slope: -0.5 (1/âˆšN scaling)

2. **Uncertainty peak at transition**:
   - Compare uncertainty for ratio < 2, 2-3, > 3
   - ANOVA: Is transition zone significantly higher?

3. **Confidence calibration**:
   - Compare Demetrios confidence to bootstrap coverage
   - "95% confidence" should cover true value 95% of time

4. **Sinkhorn convergence effect**:
   - Correlation: iterations vs uncertainty
   - More iterations â†’ better convergence â†’ lower uncertainty?

### Visualizations

1. **Uncertainty heatmap**: N vs k, color = uncertainty
2. **Phase diagram**: ratio vs Îº, error bars = uncertainty
3. **Calibration plot**: Demetrios confidence vs bootstrap coverage
4. **Scaling plot**: log(N) vs log(uncertainty)

---

## Expected Results

### Quantitative Predictions

1. **Scaling**: uncertainty âˆ N^(-0.5 Â± 0.1)
2. **Transition peak**: 2-3x higher uncertainty at ratio â‰ˆ 2.5
3. **Calibration**: Demetrios confidence within Â±5% of bootstrap
4. **Convergence**: uncertainty âˆ 1/âˆšiterations

### Qualitative Findings

- Small networks (N<100): Low confidence, high uncertainty
- Transition zone: Epistemic uncertainty captures ambiguity
- Large networks (N>500): High confidence, low uncertainty
- Demetrios automatic tracking matches manual bootstrap

---

## Success Criteria

### Must Achieve

- [x] Implement epistemic curvature in Demetrios
- [ ] Run 800 synthetic network trials
- [ ] Compare to Julia bootstrap (correlation > 0.8)
- [ ] Document uncertainty sources

### Should Achieve

- [ ] Validate 1/âˆšN scaling
- [ ] Confirm transition zone peak
- [ ] Calibrate confidence levels
- [ ] Apply to real semantic networks

### Stretch Goals

- [ ] Real-time uncertainty visualization
- [ ] Adaptive Sinkhorn (stop when confident)
- [ ] Uncertainty-based active learning
- [ ] Publish epistemic network geometry paper

---

## Timeline

**Week 1**: Implementation
- Day 1-2: Implement epistemic tracking in Demetrios
- Day 3-4: Implement Julia bootstrap comparison
- Day 5: Debug and validate

**Week 2**: Experiments
- Day 1-2: Run synthetic network sweep (800 trials)
- Day 3: Analyze results
- Day 4-5: Apply to real networks

**Week 3**: Analysis & Writing
- Day 1-2: Statistical tests and visualizations
- Day 3-4: Write results section
- Day 5: Integrate into paper

---

## Files

```
experiments/01_epistemic_uncertainty/
â”œâ”€â”€ README.md                    (this file)
â”œâ”€â”€ demetrios/
â”‚   â”œâ”€â”€ epistemic_trial.d       (single trial)
â”‚   â”œâ”€â”€ epistemic_sweep.d       (full sweep)
â”‚   â””â”€â”€ run.sh                  (execution script)
â”œâ”€â”€ julia/
â”‚   â”œâ”€â”€ bootstrap_comparison.jl (bootstrap CI)
â”‚   â””â”€â”€ analysis.jl             (statistical tests)
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ synthetic_sweep.csv     (800 trials)
â”‚   â”œâ”€â”€ real_networks.csv       (4 languages)
â”‚   â””â”€â”€ calibration.csv         (Demetrios vs bootstrap)
â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ uncertainty_heatmap.png
â”‚   â”œâ”€â”€ phase_diagram.png
â”‚   â”œâ”€â”€ calibration_plot.png
â”‚   â””â”€â”€ scaling_plot.png
â””â”€â”€ report.md                    (final writeup)
```

---

## Next Steps

1. âœ… Design complete
2. ğŸ”¨ Implement epistemic tracking in Demetrios
3. ğŸ”¨ Implement Julia bootstrap baseline
4. ğŸ§ª Run pilot experiment (N=100, k=10, 10 reps)
5. ğŸ“Š Validate measurements
6. ğŸš€ Run full experiment

---

**Status**: Ready to implement
**Owner**: Claude + Maria
**Estimated Duration**: 3 weeks
**Demetrios Features Used**: Epistemic computing, effect system, confidence tracking
