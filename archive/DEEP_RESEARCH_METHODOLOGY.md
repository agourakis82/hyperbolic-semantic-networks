# üî¨ DEEP RESEARCH METODOL√ìGICO - PAR√ÇMETROS DE CONSTRU√á√ÉO DE REDES

**Date:** 2025-11-06  
**Insight:** M√©tricas v√°lidas, PAR√ÇMETROS diferentes  
**Mission:** Encontrar par√¢metros √≥timos para social media networks  
**Principle:** HONESTIDADE ABSOLUTA [[memory:10560840]]

---

## üí° **INSIGHT CR√çTICO DO USU√ÅRIO:**

> "O segredo √© o m√©todo, n√£o o resultado. N√£o acho que as m√©tricas n√£o sejam v√°lidas, mas os par√¢metros s√£o diferentes."

**CORRETO! 100%!**

---

## üìä **PROBLEMA IDENTIFICADO:**

### **Clinical Speech Networks (PMC10031728):**
- **Method:** Semantic entities + relations (NLP pipeline)
- **Nodes:** Entities (people, objects, concepts)
- **Edges:** Semantic relations (subject-verb-object)
- **Window:** Sentence-level (grammatical structure)
- **Result:** C = 0.04-0.14 (sweet spot ‚úÖ)

### **Social Media Networks (HelaDepDet):**
- **Method:** Word co-occurrence (simple window)
- **Nodes:** Words (all words min_freq ‚â• 5)
- **Edges:** Co-occurrence within window
- **Window:** 10 words (arbitrary!)
- **Result:** C = 0.002-0.006 (too low ‚ùå)

### **Key Difference:**

**PAR√ÇMETROS DIFERENTES:**
1. **Node definition:** Entities vs. All words
2. **Edge definition:** Semantic relations vs. Co-occurrence
3. **Window size:** Sentence vs. Fixed (10 words)
4. **Min frequency:** Not specified vs. 5
5. **Network type:** Directed semantic vs. Undirected co-occurrence

---

## üéØ **DEEP RESEARCH QUESTIONS:**

### **Q1: Window Size Effect**
- Como window size afeta clustering?
- Qual window size reproduz sweet spot?
- Trade-off: pequeno (sparse) vs. grande (dense)

### **Q2: Node Selection**
- Todas palavras vs. Content words only?
- Min frequency threshold effect?
- Entity extraction vs. word tokens?

### **Q3: Edge Definition**
- Co-occurrence vs. Semantic relations?
- Directed vs. Undirected?
- Weighted by frequency vs. binary?

### **Q4: Text Preprocessing**
- Lemmatization effect?
- Stopword removal?
- POS tagging?

### **Q5: Network Construction**
- Sentence-level vs. Post-level?
- Paragraph boundaries?
- Context preservation?

---

## üî¨ **SYSTEMATIC PARAMETER SWEEP:**

### **EXPERIMENT 1: Window Size Sweep**

**Test window sizes:** 2, 3, 4, 5, 10, 20, 50, 100

**Hypothesis:**
- Small window (2-5) ‚Üí Higher clustering (more selective)
- Large window (10-100) ‚Üí Lower clustering (dense, everything connects)
- **Optimal:** Should reproduce sweet spot (C = 0.02-0.15)

**Method:**
```python
for window_size in [2, 3, 4, 5, 10, 20, 50, 100]:
    G = build_network(texts, window=window_size)
    C = nx.average_clustering(G)
    print(f"Window {window_size}: C = {C:.3f}")
```

**Expected:**
- Window 3-5: C ‚âà 0.05-0.15 (sweet spot!)
- Window 10: C ‚âà 0.002-0.006 (what we got)
- Window 50+: C ‚Üí 0 (too dense)

---

### **EXPERIMENT 2: Node Selection**

**Test strategies:**
1. **All words** (current): min_freq ‚â• 5
2. **Content words only**: Nouns, verbs, adjectives (no stopwords)
3. **Entity extraction**: NER (spaCy, NLTK)
4. **High-frequency threshold**: min_freq ‚â• 10, 20, 50

**Hypothesis:**
- Content words only ‚Üí Higher clustering (semantic coherence)
- Entities only ‚Üí Higher clustering (concept-level)
- All words ‚Üí Lower clustering (noise)

---

### **EXPERIMENT 3: Edge Definition**

**Test methods:**
1. **Co-occurrence** (current): Within window
2. **Syntactic dependency**: spaCy dependency parsing
3. **Semantic similarity**: Word embeddings (cosine > threshold)
4. **PMI (Pointwise Mutual Information)**: Statistical association

**Hypothesis:**
- Dependency parsing ‚Üí Closer to PMC10031728 (semantic relations)
- PMI ‚Üí Filters spurious co-occurrences
- Embeddings ‚Üí Semantic coherence

---

### **EXPERIMENT 4: Preprocessing**

**Test pipelines:**
1. **Minimal** (current): Lowercase + regex
2. **Standard NLP**: Lemmatization + stopword removal
3. **Advanced**: POS tagging + named entity recognition
4. **Clinical**: Domain-specific preprocessing

**Hypothesis:**
- Lemmatization ‚Üí Reduces noise, increases clustering
- Stopword removal ‚Üí Focuses on content
- NER ‚Üí Entity-level networks (like PMC10031728)

---

## üéØ **PRIORITY EXPERIMENTS:**

### **EXPERIMENT A: Window Size 3-5** ‚≠ê‚≠ê‚≠ê

**Rationale:**
- Most likely to hit sweet spot
- Fast to test
- High impact

**Action:**
```bash
python code/analysis/test_window_sizes.py \
  --data data/external/Depression_Severity_Levels_Dataset/Depression_Severity_Levels_Dataset.csv \
  --windows 2,3,4,5,10,20 \
  --n-samples 1000 \
  --output results/window_size_sweep.json
```

**ETA:** 30 minutes

---

### **EXPERIMENT B: Content Words Only** ‚≠ê‚≠ê‚≠ê

**Rationale:**
- Removes stopwords (function words)
- Focuses on semantic content
- Should increase clustering

**Action:**
```bash
python code/analysis/test_content_words.py \
  --data data/external/Depression_Severity_Levels_Dataset/Depression_Severity_Levels_Dataset.csv \
  --methods all_words,content_only,nouns_verbs,entities \
  --output results/node_selection_sweep.json
```

**ETA:** 45 minutes

---

### **EXPERIMENT C: Sentence-Level Networks** ‚≠ê‚≠ê‚≠ê

**Rationale:**
- PMC10031728 uses sentence structure
- Preserves grammatical context
- Natural semantic boundaries

**Action:**
```bash
python code/analysis/test_sentence_level.py \
  --data data/external/Depression_Severity_Levels_Dataset/Depression_Severity_Levels_Dataset.csv \
  --methods word_window,sentence_level,dependency_parse \
  --output results/construction_method_sweep.json
```

**ETA:** 1 hour

---

## ü§ñ **DARWIN AGENTS FOR METHODOLOGICAL RESEARCH:**

### **AGENT 1: LITERATURE_METHOD_MINER** üìö

**Mission:** Find how other papers construct semantic networks from text

**Search for:**
- PMC10031728 methodology section (detailed)
- Mota et al. speech graphs (method)
- Social media semantic network papers
- Best practices for text ‚Üí network

**Output:** Method comparison table

---

### **AGENT 2: PARAMETER_OPTIMIZER** üî¨

**Mission:** Systematically test all parameter combinations

**Parameters to test:**
- Window size: [2, 3, 4, 5, 10, 20]
- Min frequency: [2, 5, 10, 20]
- Node type: [all_words, content, entities]
- Edge type: [cooccur, dependency, pmi]

**Grid search:** 6 √ó 4 √ó 3 √ó 4 = 288 combinations!

**Output:** Optimal parameters for sweet spot

---

### **AGENT 3: VALIDATION_TESTER** ‚úÖ

**Mission:** Validate optimal parameters

**Tests:**
1. Does it reproduce sweet spot? (C = 0.02-0.15)
2. Does severity correlate with fragmentation?
3. Does severity correlate with KEC?
4. Cross-validation with different samples

**Output:** Validation report

---

## üìã **EXECUTION PLAN:**

### **PHASE 1: Quick Tests (Tonight, 2-3h)**

1. **Window Size Sweep** (30 min)
   - Test 2, 3, 4, 5, 10, 20
   - Find optimal for sweet spot

2. **Content Words Only** (45 min)
   - Remove stopwords
   - Test if clustering increases

3. **Sentence-Level** (1 hour)
   - Parse sentences
   - Build within-sentence networks
   - Compare to window-based

**Goal:** Find parameters that hit sweet spot!

---

### **PHASE 2: Deep Optimization (Tomorrow, 4-6h)**

4. **Grid Search** (2-3 hours)
   - All parameter combinations
   - Find global optimum

5. **Validation** (1-2 hours)
   - Cross-validate with different samples
   - Test robustness

6. **Apply to Depression** (2 hours)
   - Rebuild with optimal parameters
   - Test severity ‚Üí metrics correlation

---

### **PHASE 3: Integration (Day 3, 2-3h)**

7. **Compare Methods**
   - PMC10031728 (clinical) vs. Optimal social media
   - Document differences
   - Justify choices

8. **Update Manuscript**
   - Methods section (detailed)
   - Results with validated parameters
   - Discussion on methodology

---

## üí™ **COMMITMENT:**

**Fazer ci√™ncia CORRETA!** [[memory:10560840]]

- ‚úÖ N√£o for√ßar resultados
- ‚úÖ Testar sistematicamente par√¢metros
- ‚úÖ Documentar TODAS as escolhas
- ‚úÖ Justificar metodologia
- ‚úÖ Reportar o que funciona E o que n√£o funciona

**Se n√£o conseguirmos reproduzir sweet spot:**
- Admitir que social media ‚â† clinical speech
- Documentar diferen√ßas metodol√≥gicas
- Usar social media como complemento, n√£o main finding
- Manter foco no sweet spot discovery (10 datasets SWOW)

---

## üöÄ **STARTING DEEP RESEARCH NOW:**

**Pr√≥ximo:** Parameter sweep (window size, node selection, etc.)

**VAMOS FAZER CI√äNCIA DE VERDADE!** üî¨üí™


