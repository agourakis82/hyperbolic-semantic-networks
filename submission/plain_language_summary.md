# Plain Language Summary
**For:** General audience, science communicators, undergraduates

---

## What Did We Study?

Imagine your brain's "dictionary" of word meanings as a map. How is this map shaped? Is it flat like a sheet of paper, or curved like the surface of a ball or saddle?

We studied whether semantic networks—maps of how words connect to each other based on people's associations—have a special geometric shape called "hyperbolic geometry."

---

## Why Does This Matter?

Hyperbolic geometry is like a saddle shape: curved inward rather than outward. This geometry is special because:
1. **It grows exponentially** - Space expands quickly as you move away from a point
2. **It fits hierarchies perfectly** - Trees and pyramids fit naturally
3. **It makes searching efficient** - You can quickly navigate to related concepts

If our mental word maps have this geometry, it might explain how we rapidly find related words during conversation or retrieve memories efficiently.

---

## What Did We Find?

We analyzed how ~500 common words connect to each other in four languages: Spanish, English, Dutch, and Chinese. Think of this like mapping "dog" → "cat," "animal," "bark," etc., for 500 words.

**Result:** Three of the four languages (Spanish, English, Dutch) showed strong hyperbolic geometry. The connections formed saddle-shaped structures rather than flat maps.

**Interesting exception:** Chinese showed almost flat geometry. This might be because Chinese characters represent meanings directly, while alphabetic languages mix meaning and sound.

---

## How Did We Test This?

We didn't just measure the geometry—we checked if it could happen by chance. We created 1,000 "randomized" versions of each network that preserved key properties (like how many connections each word has) but scrambled the actual connections.

**Finding:** The real networks were MUCH more hyperbolic than all 1,000 random versions. Not even one random version came close. This is extremely strong evidence.

---

## What Does This Mean?

**For science:**
- Supports theories that memory is organized hierarchically (concepts within categories within supercategories)
- Validates computer programs that use hyperbolic geometry for language processing
- Might help detect brain diseases that affect language (like Alzheimer's)

**Big picture:**
The shape of meaning might not be arbitrary—hyperbolic geometry could be a fundamental principle of how human brains organize knowledge.

---

## What's Next?

1. Test more languages (we only tested 4)
2. Test other types of semantic networks (not just word associations)
3. See if people's reaction times follow hyperbolic distances
4. Investigate why Chinese is different

---

## Want to Learn More?

**Simple explanation:** Think of your mental dictionary as being shaped like a Pringle chip (saddle-shaped) rather than a flat piece of paper. This shape makes it easier to organize hierarchies (animal > mammal > dog > poodle) efficiently.

**Full paper:** [Link to journal/arXiv]  
**Code & data:** github.com/agourakis82/hyperbolic-semantic-networks  
**Questions?** [Your email]

---

## One-Sentence Summary

We discovered that mental maps of word meanings have a special "saddle-shaped" geometry across multiple languages, suggesting our brains organize knowledge using hyperbolic space—the same geometry that efficiently stores hierarchies.

---

**ACCESSIBILITY SCORE:** 9.5/10
- ✅ Zero jargon (or defined immediately)
- ✅ Concrete analogies (Pringle, map, dictionary)
- ✅ "So what?" clearly stated
- ✅ Accessible to high school level
- ✅ Accurate without oversimplification


