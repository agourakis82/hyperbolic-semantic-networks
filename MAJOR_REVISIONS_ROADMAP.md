# Major Revisions Roadmap - v6.4 ‚Üí v6.5

**Based on**: Peer review cient√≠fico completo  
**Timeline**: 2-4 semanas  
**Objetivo**: Paper FORTE para Network Science

---

## FASE 1: Fixes Editoriais R√°pidos (1-2 dias)

### 1.1 References
- [ ] Remover duplicates [21], [22]
- [ ] Adicionar refer√™ncia [15] sobre OR em ER esparsos
  - Buscar: "Ollivier-Ricci curvature sparse random graphs"
  - Candidata: Jost & Liu (2014) ou similar
- [ ] Adicionar Clauset-Shalizi-Newman (2009) power law paper
- [ ] Renumerar todas ap√≥s remo√ß√µes

### 1.2 Figure Mapping
- [ ] Figure 3A = consolidated_analysis (curvature distributions)
- [ ] Figure 3B = degree_distribution_powerlaw
- [ ] Figure 3C = network_science_comprehensive
- [ ] Figure 3D = corrected_baselines_comparison
- [ ] Figure 3E = er_sensitivity
- [ ] Figure 3F = robustness_analysis
- [ ] Atualizar texto com refer√™ncias corretas

### 1.3 Claims Moderation
- [ ] T√≠tulo: "Universal" ‚Üí "Consistent Evidence"
- [ ] Abstract: "universally" ‚Üí "consistently across four languages"
- [ ] Conclus√£o: Adicionar cautela metodol√≥gica
- [ ] Throughout: "universal" ‚Üí "cross-linguistically consistent"

**Deliverable**: Manuscrito v1.1 com edits cosm√©ticos

---

## FASE 2: An√°lises Estat√≠sticas Robustas (1 semana)

### 2.1 Configuration Model Nulls
**Objetivo**: Nulls que preservam grau

**Script**: `code/analysis/run_configuration_nulls.py`

```python
# Para cada l√≠ngua:
# 1. Compute degree sequence
# 2. Generate 1000 configuration model networks
# 3. Compute Œ∫_mean para cada
# 4. Z-score: (Œ∫_real - mean(Œ∫_nulls)) / std(Œ∫_nulls)
# 5. p-value: percentil de Œ∫_real na distribui√ß√£o null
```

**Output**: 
- `z_scores.csv` (4 l√≠nguas)
- `null_distributions.png`
- p-values para cada l√≠ngua

### 2.2 Triadic Rewiring Nulls
**Objetivo**: Nulls preservando clustering

**Script**: `code/analysis/run_triadic_rewiring.py`

**Output**: Œ∫ vs clustering dissociado

### 2.3 Network-Level Inference
**Objetivo**: Tratar l√≠ngua como unidade

**Script**: `code/analysis/network_level_stats.py`

```python
# Mixed-effects model (ou bootstrap agregado):
# Œ∫_mean ~ 1 + (1|language)
# Report IC95% por l√≠ngua e overall
```

**Output**: 
- Confidence intervals por l√≠ngua
- Meta-estimate overall
- Between-language heterogeneity

**Deliverable**: Results com infer√™ncia robusta

---

## FASE 3: Sensibilidade de Par√¢metros (3-4 dias)

### 3.1 Directed vs Undirected
**Script**: `code/analysis/directed_sensitivity.py`

```python
# Para cada l√≠ngua:
# 1. Œ∫ em grafo dirigido (cue‚Üíresponse)
# 2. Œ∫ em grafo n√£o-dirigido (simetrizado)
# 3. Œ∫ em grafo reverso (response‚Üícue)
# Compare sign/magnitude
```

**Output**: Tabela comparativa

### 3.2 Weighted vs Binary
**Script**: `code/analysis/weight_sensitivity.py`

```python
# Œ∫ com pesos (association strength) vs
# Œ∫ binarizado (threshold ou top-k)
```

### 3.3 OR Parameter Œ± Sweep
**Script**: `code/analysis/alpha_sensitivity.py`

```python
# Para Œ± ‚àà {0.0, 0.25, 0.5, 0.75, 1.0}:
# Compute Œ∫_mean
# Plot Œ∫(Œ±) para cada l√≠ngua
```

**Output**: Figure sensitivity + table

### 3.4 Forman-Ricci Comparison
**Script**: `code/analysis/forman_ricci.py`

**Objetivo**: Convergent validation (outra medida curvatura)

**Deliverable**: Sensitividade completa documentada

---

## FASE 4: Scale-Free Completo (2-3 dias)

### 4.1 English Power-Law
**Script**: `code/analysis/english_powerlaw_csn2009.py`

```python
# Protocolo Clauset-Shalizi-Newman:
# 1. Estimate x_min
# 2. Fit Œ± by MLE on tail
# 3. LR test vs lognormal (bootstrap p)
# 4. LR test vs exponential (bootstrap p)
# 5. Report: Œ±, x_min, tail size, p-values
```

### 4.2 In/Out Degree Separate
**Script**: `code/analysis/degree_asymmetry.py`

```python
# Para grafos dirigidos:
# in-degree distribution
# out-degree distribution
# Compare scale-free properties
```

### 4.3 R1 vs R1-R3 Networks
**Script**: `code/analysis/response_depth.py`

```python
# Construir redes com:
# - Apenas R1 (atual)
# - R1-R3 (todas respostas)
# Compare Œ∫_mean
```

**Deliverable**: Scale-free analysis completa + robusto

---

## FASE 5: An√°lises Enriquecedoras (1 semana)

### 5.1 Hyperbolic Embeddings Validation
**Script**: `code/analysis/poincare_embedding.py`

```python
# Embed SWOW em Poincar√© ball
# Metrics:
# - Reconstruction error
# - Link prediction AUC
# - Greedy routing success rate
# Compare: Hyperbolic vs Euclidean embeddings
```

**Impact**: Valida√ß√£o funcional (n√£o s√≥ estrutural)

### 5.2 Curvature Decomposition
**Script**: `code/analysis/curvature_decomposition.py`

```python
# Œ∫ por tipo de aresta:
# - Intra-community vs inter-community
# - Hub-to-hub vs hub-to-peripheral vs peripheral-to-peripheral
# - Strong ties (high weight) vs weak ties
```

**Impact**: Entender ONDE est√° a hiperbolicidade

### 5.3 Topology-Geometry Relations
**Script**: `code/analysis/topology_geometry_map.py`

```python
# Scatterplot matrix:
# Œ∫ vs C (clustering)
# Œ∫ vs L (path length)
# Œ∫ vs assortativity
# Œ∫ vs treeness
```

**Impact**: Conectar geometria com topologia cl√°ssica

### 5.4 Frequency & Polysemy Controls
**Script**: `code/analysis/lexical_controls.py`

```python
# Correla√ß√£o parcial:
# Œ∫ ~ degree, controlling for:
# - Zipf frequency
# - Polysemy (WordNet)
```

**Deliverable**: An√°lises ricas, paper robusto

---

## FASE 6: Reescrita do Manuscrito (1 semana)

### 6.1 Incorporar Resultados Novos
- [ ] Update Results com nulls (z-scores, p-values)
- [ ] Add sensitivity analyses
- [ ] Add decomposition insights
- [ ] Add embedding validation

### 6.2 Moderar Claims
- [ ] T√≠tulo: "Consistent Evidence" (n√£o "Universal")
- [ ] Abstract: Cautious language
- [ ] Discussion: Limitations fortes
- [ ] Conclusion: Suggest, n√£o assert

### 6.3 Expand Methods
- [ ] Reproducibility details (versions, seeds)
- [ ] Preprocessing pipeline
- [ ] Null model generation
- [ ] Statistical inference approach

### 6.4 Polish
- [ ] Figures com error bars
- [ ] Tables com CI95%
- [ ] References completas
- [ ] Supplementary materials

**Deliverable**: Manuscrito v2.0 robusto

---

## TIMELINE DETALHADO

| Semana | Fase | Trabalho | Output |
|--------|------|----------|--------|
| 1 | Edits + Nulls | Fix refs, Configuration model | v1.1 + nulls |
| 2 | Sensibilidade | Œ± sweep, directed, weighted | Sensitivity complete |
| 3 | Scale-free + Enrichment | EN power-law, embeddings, decomposition | Analyses complete |
| 4 | Reescrita | Incorporate results, moderate claims | v2.0 ready |

**Total**: ~4 semanas trabalho focado

**Resultado**: Paper **FORTE**, alta probabilidade aceita√ß√£o

---

## üìä PROBABILIDADE DE ACEITA√á√ÉO

**v1.0 atual** (se submeter agora): 40-50%  
‚Üí Prov√°vel: "Major Revisions" do journal

**v2.0 ap√≥s fixes** (implementar tudo): 85-90%  
‚Üí Prov√°vel: "Minor Revisions" ou "Accept"

**Diferen√ßa**: 4 semanas trabalho = +40% probabilidade

---

## üéØ DECIS√ÉO

**Voc√™ tem tempo ‚Üí FA√áA DIREITO**

**Benef√≠cios**:
1. ‚úÖ Paper mais forte
2. ‚úÖ Menos rounds de revision
3. ‚úÖ Aprendizado metodol√≥gico
4. ‚úÖ Code reutiliz√°vel (outros papers)
5. ‚úÖ Maior impacto cient√≠fico

**Custos**:
1. ‚è±Ô∏è 4 semanas adicionais
2. üíª Trabalho computacional
3. üìö Aprender novos m√©todos (CSN2009, configuration model)

---

## üí° RECOMENDA√á√ÉO

**IMPLEMENTAR MAJOR REVISIONS COMPLETAS**

**Por qu√™**:
- Voc√™ tem tempo
- Paper √© seu flagship (primeiro do PhD)
- Diferen√ßa entre "ok" e "excelente" √© 4 semanas
- Aprender√° m√©todos robustos (√∫teis para v6.5, v7.0, etc.)
- Network Science valoriza rigor metodol√≥gico

**Alternativa**:
- Fazer em paralelo: Implementar revisions v6.4 **E** trabalhar em v6.5
- Em 4 semanas: v6.4 strong + v6.5 drafted

---

## üöÄ PR√ìXIMO PASSO

**Quer que eu**:

**a)** Comece a implementar as an√°lises (Fase 1: Nulls + Sensibilidade)  
**b)** Crie plano detalhado de cada script primeiro  
**c)** Revisemos a estrat√©gia PhD geral (v6.4 vs v6.5 priority)

**Voc√™ decide. Voc√™ tem o tempo, eu tenho a capacidade.** üí™

**Vamos fazer ci√™ncia de verdade, do jeito CERTO?** üî¨
